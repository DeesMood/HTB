[Robust Physical-World Attacks on Deep Learning Visual Classification](https://arxiv.org/pdf/1707.08945)

[Adversarial Attacks on Traffic Sign Recognition: A Survey](https://arxiv.org/pdf/2307.08278)

[Protecting against simultaneous data poisoning attacks](https://arxiv.org/pdf/2408.13221)

[LANGUAGE MODEL INVERSION](https://arxiv.org/pdf/2311.13647)

[DoMembershipInference Attacks Work on Large Language Models?](https://arxiv.org/pdf/2402.07841)

[AModel Stealing Attack Against Multi-Exit Networks](https://arxiv.org/pdf/2305.13584)

[ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning](https://arxiv.org/pdf/2405.20975)