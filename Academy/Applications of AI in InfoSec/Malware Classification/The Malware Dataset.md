The dataset of malware images we will be using is the `malimg` dataset, which we can obtain [here](https://drive.google.com/file/d/1M83VzyIQj_kuE9XzhClGK5TZWh1T_pr-/view) or [here](https://www.kaggle.com/api/v1/datasets/download/ikrambenabd/malimg-original). It was proposed in [this](https://dl.acm.org/doi/10.1145/2016904.2016908) paper.

## Malimg Dataset

We can download and unpack the dataset using the following commands:

```shell-session
JustSomeRedTeamer@htb[/htb]$ wget https://www.kaggle.com/api/v1/datasets/download/ikrambenabd/malimg-original -O malimg.zip

JustSomeRedTeamer@htb[/htb]$ unzip malimg.zip
```

The dataset consists of 9339 image files for 25 different malware families. The dataset is organized in folders, where each folder contains all samples for a single malware family. The folder name corresponds to the malware family's name:

```shell-session
JustSomeRedTeamer@htb[/htb]$ ls malimg_paper_dataset_imgs

 Adialer.C        C2LOP.P          Lolyda.AA3      'Swizzor.gen!I'
 Agent.FYI        Dialplatform.B   Lolyda.AT        VB.AT
 Allaple.A        Dontovo.A       'Malex.gen!J'     Wintrim.BX
 Allaple.L        Fakerean         Obfuscator.AD    Yuner.A
'Alueron.gen!J'   Instantaccess   'Rbot!gen'
 Autorun.K        Lolyda.AA1       Skintrim.N
'C2LOP.gen!g'     Lolyda.AA2      'Swizzor.gen!E'
```

Each image contains a visual representation of a PE file, which is a Windows executable. The images are grayscale in `png` format:

![](Pasted%20image%2020250823220202.png)

These images are a direct representation of the malware binaries. Each pixel in the image represents a single byte in the binary. The byte can be any value in the 0-255 range. The exact value is represented in the corresponding pixel's brightness. A byte with the value `0` results in a black pixel, a value of `255` results in a white pixel, and a value in between results in the corresponding gray pixel.

![](Pasted%20image%2020250823220604.png)

Each binary byte is fully encoded within the image, meaning the image can be used to exactly reconstruct the binary without any loss of information. Furthermore, the images can visibly convey patterns in the binary. For instance, consider the following two image samples from the `FakeRean` malware family. We can see distinct patterns in both malware images.

![](Pasted%20image%2020250823221319.png)

![](Pasted%20image%2020250823221324.png)

## Exploring the Dataset

To familiarize ourselves with the dataset, let's start exploring it by creating a plot of the class distribution within it. This enables us to spot classes that are over- or underrepresented.

```python
import os
import matplotlib.pyplot as plt
import seaborn as sns

DATA_BASE_PATH = "./malimg_paper_dataset_imgs/"
```

Afterward, we can iterate over all malware families and count the number of images within the corresponding folder to compute the overall class distribution:

```python
# compute the class distribution
dist = {}
for mlw_class in os.listdir(DATA_BASE_PATH):
    mlw_dir = os.path.join(DATA_BASE_PATH, mlw_class)
    dist[mlw_class] = len(os.listdir(mlw_dir))
```

Finally, we can create a barplot to visualize the class distribution:

```python
# plot the class distribution

# HTB Color Palette
htb_green = "#9FEF00"
node_black = "#141D2B"
hacker_grey = "#A4B1CD"

# data
classes = list(dist.keys())
frequencies = list(dist.values())

# plot
plt.figure(facecolor=node_black)
sns.barplot(y=classes, x=frequencies, edgecolor = "black", orient='h', color=htb_green)
plt.title("Malware Class Distribution", color=htb_green)
plt.xlabel("Malware Class Frequency", color=htb_green)
plt.ylabel("Malware Class", color=htb_green)
plt.xticks(color=hacker_grey)
plt.yticks(color=hacker_grey)
ax = plt.gca()
ax.set_facecolor(node_black)
ax.spines['bottom'].set_color(hacker_grey)
ax.spines['top'].set_color(node_black)
ax.spines['right'].set_color(node_black)
ax.spines['left'].set_color(hacker_grey)
plt.show()
```

From the resulting diagram, we can identify which malware families are represented more than others, potentially skewing the model. Suppose the trained model does not provide the expected performance in accuracy, number of false positives, and number of false negatives. In that case, we may want to fine-tune the dataset before training to ensure a more balanced class distribution.

![](Pasted%20image%2020250824005538.png)


