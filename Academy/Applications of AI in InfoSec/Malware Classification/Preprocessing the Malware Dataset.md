We need to prepare the data before we can feed the images to a CNN for training and inference. In particular, we need to split the data into two distinct datasets: a training and a test set. Furthermore, we need to apply the preprocessing functions expected by our model so the model can work on the images. Lastly, we must createÂ `DataLoaders`Â that we can use during training and inference.

## Preparing the Datasets

To split the data into two distinct datasets, one for training and one for testing, we will use the libraryÂ [split-folders](https://pypi.org/project/split-folders/), which we can install withÂ `pip`:

```shell-session
JustSomeRedTeamer@htb[/htb]$ pip3 install split-folders
```

Afterward, we can use the following code to split the data accordingly. We will use anÂ `80-20`Â split, meaning 80% of the data will be used for training and 20% for testing:

```python
import splitfolders

DATA_BASE_PATH = "./malimg_paper_dataset_imgs/"
TARGET_BASE_PATH = "./newdata/"

TRAINING_RATIO = 0.8
TEST_RATIO = 1 - TRAINING_RATIO

splitfolders.ratio(input=DATA_BASE_PATH, output=TARGET_BASE_PATH, ratio=(TRAINING_RATIO, 0, TEST_RATIO))
```

After running the code once, a new directoryÂ `./newdata/`Â will be created containing three folders:

![](Pasted%20image%2020250824032922.png)

TheÂ `test`Â folder contains the test dataset, theÂ `train`Â folder contains the training dataset, and theÂ `val`Â folder contains the validation dataset. In this case, we will not use a validation data set, which is why the validation data set is empty. We can confirm the 80-20 split by counting the number of files in each dataset:

![](Pasted%20image%2020250824033205.png)

The split was successful, as we can see. We can now createÂ `DataLoaders`Â for training and inference and apply the required preprocessing to the images.

## Applying Preprocessing & Creating DataLoaders

In the first step, let us define the preprocessing required for our model to read the data. For CNNs, this typically requires a resizing such that all input images are the same size and a normalization. Normalization ensures that the data is standardized before the data is fed to the model. This results in a model that is easier to train. In PyTorch, our preprocessing looks like this:

```python
from torchvision import transforms

# Define preprocessing transforms
transform = transforms.Compose([
	transforms.Resize((75, 75)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```

`transforms.Normalize(mean, std)` applies this to **each channel**:

xnorm=xâˆ’meanstdx_{norm} = \frac{x - \text{mean}}{\text{std}}xnormâ€‹=stdxâˆ’meanâ€‹

- `x` = pixel value (in `[0,1]`)
    
- `mean` = average brightness of that channel
    
- `std` = standard deviation (how spread out values are)

### 3. Why these numbers?

The `mean = [0.485, 0.456, 0.406]` and  
`std = [0.229, 0.224, 0.225]`

ðŸ‘‰ come from the **ImageNet dataset** (millions of images).  
They represent the **average color and contrast** of ImageNet images.

- Red channel avg â‰ˆ 0.485
    
- Green channel avg â‰ˆ 0.456
    
- Blue channel avg â‰ˆ 0.406

Afterward, we can load the datasets from their corresponding folders and apply the preprocessing functions. We need to specify the root folder for each dataset in theÂ `root`Â parameter and the preprocessing transform in theÂ `transform`Â parameter. As we have discussed above, the root folders for the datasets areÂ `./newdata/train/`Â andÂ `./newdata/test/`, respectively.

```python
from torchvision.datasets import ImageFolder
import os

BASE_PATH = "./newdata/"

# Load training and test datasets
train_dataset = ImageFolder(
	root=os.path.join(BASE_PATH, "train"),
    transform=transform
)

test_dataset = ImageFolder(
	root=os.path.join(BASE_PATH, "test"),
    transform=transform
)
```

Finally, we can createÂ `DataLoader`Â instances, which we can use to iterate over the data for training and inference. We can supply a batch size and specify the number of workers to load the data in theÂ `num_workers`Â parameter. This enables parallelization and will speed up the data handling:

```python
from torch.utils.data import DataLoader

TRAIN_BATCH_SIZE = 1024
TEST_BATCH_SIZE = 1024

# Create data loaders
train_loader = DataLoader(
    train_dataset,
	batch_size=TRAIN_BATCH_SIZE,
    shuffle=True,
    num_workers=2
)
    
test_loader = DataLoader(
    test_dataset,
    batch_size=TEST_BATCH_SIZE,
    shuffle=False,
    num_workers=2
)
```

Let us take a look at one of the preprocessed images to see its effects:

```python
import matplotlib.pyplot as plt

# HTB Color Palette
htb_green = "#9FEF00"
node_black = "#141D2B"
hacker_grey = "#A4B1CD"

# image
sample = next(iter(train_loader))[0][0]

# plot
plt.figure(facecolor=node_black)
plt.imshow(sample.permute(1,2,0))
plt.xticks(color=hacker_grey)
plt.yticks(color=hacker_grey)
ax = plt.gca()
ax.set_facecolor(node_black)
ax.spines['bottom'].set_color(hacker_grey)
ax.spines['top'].set_color(node_black)
ax.spines['right'].set_color(node_black)
ax.spines['left'].set_color(hacker_grey)
ax.tick_params(axis='x', colors=hacker_grey)
ax.tick_params(axis='y', colors=hacker_grey)
plt.show()
```

![](Pasted%20image%2020250824044323.png)

The details can be roughly discerned from the raw image. However, many of the fine details have been lost.

After combining the above code into a single function, we end up with the following code:

```python
from torchvision import transforms
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import os

def load_datasets(base_path, train_batch_size, test_batch_size):
    # Define preprocessing transforms
    transform = transforms.Compose([
        transforms.Resize((75, 75)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # Load training and test datasets
    train_dataset = ImageFolder(
        root=os.path.join(base_path, "train"),
        transform=transform
    )

    test_dataset = ImageFolder(
        root=os.path.join(base_path, "test"),
        transform=transform
    )

    # Create data loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=train_batch_size,
        shuffle=True,
        num_workers=2
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=test_batch_size,
        shuffle=False,
        num_workers=2
    )

    n_classes = len(train_dataset.classes)
    return train_loader, test_loader, n_classes
```

- You have the **Malimg dataset**, which contains **25 malware classes** (categories).
    
- Instead of **hardcoding `25`**, the function **counts the classes dynamically** (by reading folders or labels from the dataset).

This makes your code **reusable and robust**, especially in research or production where datasets evolve.

You donâ€™t want to manually update every script whenever class counts change â€” instead, the code adapts itself.


